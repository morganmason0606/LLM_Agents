{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loader = PyPDFLoader\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) \n",
    "PATH_TO_PDFS = './reports/24Q1USBANK'\n",
    "def return_splits(path, file_loader, text_splitter):\n",
    "    docs = []\n",
    "    for f in os.listdir(path):\n",
    "        dir_path = os.path.join(path, f)\n",
    "        if os.path.isfile(dir_path):\n",
    "                loader = file_loader(dir_path)\n",
    "        docs.extend(loader.load())\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import  ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Read the content and determine if it contains information relevant to the question. If no relevant information is containted, respond simply with \"NONE\". If relevant information is contained, tell me briefly what the content relevant to the question is.\"\"\"),\n",
    "   (\"human\", \"Content: \\n {content} \\n\\n Question: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Read the content and determine if it contains information relevant to the question. If no relevant information is containted, respond simply with \"NONE\". If relevant information is contained, tell me briefly what the content relevant to the question is.'), HumanMessage(content='Content: \\n this is content \\n\\n Question: this is question')])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"content\": \"this is content\", \"question\": \"this is question\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chain = RunnableParallel({\n",
    "    \"question\" : lambda i : i['question'],\n",
    "    \"content\" : lambda i: i['content']\n",
    "}) | prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableSequence(\n",
    "    RunnableLambda(lambda inp: prompt_chain.batch([{\"question\": inp['question'], \"content\" : s} for s in inp['docs']])) , \n",
    "    RunnableLambda(lambda prompts: llm.batch(inputs=prompts))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how have financial statement changed over since Q1\"\n",
    "splits = return_splits(path='./reports/24Q1USBANK', file_loader=file_loader, text_splitter=text_splitter)\n",
    "earnings_call_pres_splits = [s for s in splits if s.metadata['source'] == './reports/24Q1USBANK\\\\2Q24-Earnings-Call-Presentation.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke({\"question\" : question, \"docs\" : earnings_call_pres_splits})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NONE'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', \"+w\") as f:\n",
    "    for i, r in enumerate(res, 1): \n",
    "        f.write(f\"split {i}\\n\")\n",
    "        f.write(f\"{r.content}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
