{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation chat bot\n",
    "this notebook explores using llm to set up chatbot for documentation\n",
    "* this chatbot should be able to answer basic questions and provide the documents that were used to generate its responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there were many good resources from langchain about this appliaction\n",
    "* https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "* https://python.langchain.com/v0.1/docs/use_cases/question_answering/citations/\n",
    "* https://www.youtube.com/watch?v=Vw52xyyFsB8&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making doc loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = r\"./text\"\n",
    "docs = []\n",
    "\n",
    "for f in listdir(mypath):\n",
    "    file_path = join(mypath, f)\n",
    "    if isfile(file_path):\n",
    "        loader = TextLoader(file_path, encoding='utf8')\n",
    "        docs.extend(loader.load())\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "import os\n",
    "from os.path import  join\n",
    "\n",
    "\n",
    "\n",
    "def get_retriever(path_to_docs= \"./text\", force_reembed=False):\n",
    "    if(not os.path.exists(\"faiss_index\") or force_reembed):\n",
    "\n",
    "        docs = []\n",
    "        for f in os.listdir(path_to_docs):\n",
    "            file_path = join(path_to_docs, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                loader = TextLoader(file_path, encoding='utf8')\n",
    "                docs.extend(loader.load())\n",
    "\n",
    "\n",
    "        vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())\n",
    "        vectorstore.save_local(\"faiss_index\")\n",
    "    else: \n",
    "        vectorstore = FAISS.load_local(\"faiss_index\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "retriever = get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\") #pulled prompt from langchain prompt repo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "\n",
    "my_prompt = ChatPromptTemplate(\n",
    "    input_variables=['context','question'],\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['context', 'question'], \n",
    "                template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local and citing sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question =  Which countries have a major service sector\n",
      "answer =  The United Kingdom, India, and Japan have major service sectors contributing a significant portion to their GDP. The service sector in the United Kingdom accounts for 82% of GDP, in India over 50% of GDP, and in Japan approximately 70% of GDP.\n",
      "Documents used:\n",
      "\tsource: ./text\\econ_uk.txt\tThe service sector dominates, contributi...otland being the richest areas\n",
      "\tsource: ./text\\econ_india.txt\tThe service sector makes up more than 50... at 29.3% of GDP in 2022.[104]\n",
      "\tsource: ./text\\econ_japan.txt\tJapan has a highly service-dominated eco...panies are based in Japan.[41]\n",
      "\tsource: ./text\\econ_uk.txt\tThe United Kingdom has one of the most g...oughly 24.5% of GDP.[4][38][3]\n"
     ]
    }
   ],
   "source": [
    "def ask_question(question):\n",
    "    ans = rag_chain_with_source.invoke(question)\n",
    "    print(\"question = \",ans[\"question\"])\n",
    "    print(\"answer = \", ans['answer'])\n",
    "    print(\"Documents used:\")\n",
    "    for d in ans['context']:\n",
    "        if len(d.page_content) > 40:\n",
    "            print(\"\\tsource: \"+d.metadata['source']+\"\\t\"+d.page_content[:40]+\"...\"+d.page_content[-30:])\n",
    "        else:\n",
    "            print(\"\\tsource: \"+d.metadata['source']+\"\\t\"+d.page_content)\n",
    "ask_question(\"Which countries have a major service sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "of note is that the US text only mentions that its economy dominates the service trade but not how big it is relatively\n",
    "> The U.S. not only has the largest internal market for goods, but also dominates the services trade.  \n",
    "\n",
    "this could be fixed with more specific querying or more explicit documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
