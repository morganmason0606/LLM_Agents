{
	// Place your LLM_Agents workspace snippets here. Each snippet is defined under a snippet name and has a scope, prefix, body and 
	// description. Add comma separated ids of the languages where the snippet is applicable in the scope field. If scope 
	// is left empty or omitted, the snippet gets applied to all languages. The prefix is what is 
	// used to trigger the snippet and the body will be expanded and inserted. Possible variables are: 
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. 
	// Placeholders with the same ids are connected.
	// Example:
	// "Print to console": {
	// 	"scope": "javascript,typescript",
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }
	"load .env file using dotenv":{
		"scope":"jupyter, python", 
		"prefix":"load_env_var", 
		"body":[
			"%load_ext dotenv",
			"%dotenv ../.env"
		],
		"description": "load .env file using dotenv"
	},
	"load models":{
		"scope":"jupyter, python", 
		"prefix": " load_model",
		"body": [
			"from langchain_openai import OpenAIEmbeddings, ChatOpenAI",
			"llm = ChatOpenAI(model=\"gpt-4o-mini\")",
			"embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
		]
	},
	"load docs to vector database":{
		"scope":"jupyter, python", 
		"prefix": " load_docs_to_vdb",
		"body":[
"from langchain_community.vectorstores import FAISS",
"from langchain_text_splitters import RecursiveCharacterTextSplitter",
"from langchain_community.document_loaders import PyPDFLoader",
"import os",
"file_loader = PyPDFLoader",
"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) ",
"",
"PATH_TO_PDFS = '$1'",
"INDEX_PATH = os.path.join(PATH_TO_PDFS, 'faiss_index') ",
"if(not os.path.exists(INDEX_PATH)):",
"    docs = []",
"    for f in os.listdir(PATH_TO_PDFS):",
"        dir_path = os.path.join(PATH_TO_PDFS, f)",
"        if os.path.isfile(dir_path):",
"                loader = file_loader(dir_path)",
"        docs.extend(loader.load())",
"    splits = text_splitter.split_documents(docs)",
"    vectorstore = FAISS.from_documents(splits, embedding_model)",
"    vectorstore.save_local(INDEX_PATH)",
"else:",
"    vectorstore = FAISS.load_local(INDEX_PATH, embedding_model, allow_dangerous_deserialization=True)"
		]
	},
	"make field":{
		"scope":"jupyter, python", 
		"prefix": " pyfield",
		"body": [
" $1 : float = Field(description=\"$1\")",
		]

	},
	
}