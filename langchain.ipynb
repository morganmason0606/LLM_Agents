{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-core is the package containing core components: llms, vector db, retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-community provides many integrations  \n",
    "* langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain is the main package with chains, agents, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph helps build more robust actors  \n",
    "langserv to turn it into a rest api   \n",
    "* these two are less relevant\n",
    "  \n",
    "langsmith to heldp debug, test, eval, monitor develop apps\n",
    "* this is likely relevant for developing more complicated applications, but is a paid service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lanchain expression language (LCEL)  \n",
    "declaritive way to chain langchain components  \n",
    "* simplest chain is prompt -> llm : create a prompt template to control input and feed it to a llm  \n",
    "* also good at parallel execution, declaring retries + fallbacks, can stream intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable interface  \n",
    "most interfaces implement Runnable protocls\n",
    "* stream: stream back chunks of the response\n",
    "* invoke: call the chain on an input\n",
    "* batch: call the chain on a list of inputs\n",
    "* async equiv by adding 'a' in front: astream, ainvoke, abatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components: LC provides standard components useful for builing llms\n",
    "* chat models: use text as input and output, usually newer models\n",
    "    * initiallizing model includes; name of model, api key, base url to send requests to \n",
    "* Messages: ai and human messages differentiated, both include fields for role, content, and metadata\"\n",
    "    * ai messages also have additional feels to better track what is being used\n",
    "    * there are other message for different systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates\n",
    "templates help force the input to be in a specific format\n",
    "can be in the form of a string or as a message\n",
    "* PromptTemplate.from_template(\"Tell me a joke about {topic}\").invoke({\"topic\": \"cats\"})\n",
    "* `ChatPromptTemplate.from_messages([  \n",
    "    (\"system\", \"You are a helpful assistant\"),  \n",
    "    (\"user\", \"Tell me a joke about {topic}\")  \n",
    "]).invoke({\"topic\": \"cats\"})`\n",
    "  \n",
    "system is used to describe how the model should function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output parsers\n",
    "responsible for taking model output and translating it to a specifc format\n",
    "* json, xml, csv, yaml, pandas df, ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loaders\n",
    "load documents, many integratiosn for different soruces\n",
    "\n",
    "### text splitters\n",
    "it is advantageous to split long documents into smaller chunks that do not excede context window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Stores\n",
    "common wat to store and search over unstrucutred dtat is to embed it  \n",
    "* documents are embedded and stored in a database\n",
    "* when you query a vector store, you create an idea of the types of embeddings you are looking for and retrieve the documents with near-by embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers\n",
    "interfece to return documents given unstructured query  \n",
    "more general than vector store\n",
    "* doesn't need to store documents, just retrieve them\n",
    "* take a query string, returns a list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools\n",
    "if you can describe the interface of a tool and explain it in json, you should be able to get a chat model to interact with it\n",
    "* may require fine tuning\n",
    "* better names, descriptions, json schemas describing the tools leads to better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### toolkits\n",
    "toolkits are collections of tools intended for use together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "Agents use llm as reasoning engine to determin which actions to take and how to take them \n",
    "* langgraph is made to explicity make this easier\n",
    "* common framework: ReAct agents\n",
    "    * reason, act agents; it reasons what it should do -> it acts -> it observes the outcome and reasons on what next to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks \n",
    "help hook into the stages of llm appication, useful for logging, monitoring, streaming, other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL\n",
    "[lcel](https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/) is the language to chain operations together\n",
    "* they can be chained sequentailly or done in parallel / in batches"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
